{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_M30.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[df['oldID'].str.contains('PM1.*1$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.loc[new_df['oldID'].str.len() == 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['KM'] = new_df[\"oldID\"].str[3:5].astype(str) + \".\" + new_df[\"oldID\"].str[5:6].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df['fecha'].str.contains('2015-08-04')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[['KM']] = new_df.loc[:,['KM']].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[:, 'densidad'] = new_df.loc[:, \"intensidad\"] / new_df.loc[:, \"vmed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dropna(subset = ['densidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Hora'] = new_df[\"fecha\"].str[11:13].astype(str) + \".\" + new_df[\"fecha\"].str[14:16].astype(str)\n",
    "new_df[['Hora']] = new_df.loc[:,['Hora']].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sort_values('Hora').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.plot.scatter(x=\"densidad\", y=\"Hora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('df_M30_KM_dia.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database of one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leo el CSV y dibujo los scatter\n",
    "\n",
    "df_un_dia = pd.read_csv('df_M30_KM_dia.csv', delimiter=';')\n",
    "df_un_dia.plot.scatter(x=\"densidad\", y=\"Hora\")\n",
    "df_un_dia.plot.scatter(x=\"Hora\", y=\"KM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordeno el dataframe por KM y Horas y quito las mediciones erróneas\n",
    "\n",
    "df_prueba = df_un_dia.copy()\n",
    "df_prueba = df_prueba.sort_values(by=['KM', 'Hora'])\n",
    "df_prueba = df_prueba.reset_index(drop=True)\n",
    "df_prueba = df_prueba[['ID', 'oldID', 'fecha', 'intensidad', 'ocupacion', 'vmed', 'periodo_integracion',\n",
    "                       'KM', 'densidad', 'Hora']]\n",
    "df_prueba = df_prueba[~(df_prueba['KM'] == 0.2)]\n",
    "df_prueba = df_prueba[~(df_prueba['KM'] == 0.9)]\n",
    "df_prueba.index = range(len(df_prueba.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genero un dataframe nuevo para las interpolaciones (15 minutos -> 1 minuto)\n",
    "\n",
    "nans = np.where(np.empty_like(np.arange(576000).reshape(57600, 10)), np.nan, np.nan)\n",
    "df_new = pd.DataFrame(nans, columns=['ID','oldID','fecha','intensidad','ocupacion','vmed','periodo_integracion', \n",
    "                                     'KM', 'densidad', 'Hora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asigno los valores registrados cada 15 columnas y el resto como NaN para interpolar.\n",
    "\n",
    "j = 0\n",
    "for i in df_new.index.values.astype(int):\n",
    "    print(\"i: \", i, \"j: \", j)\n",
    "    if (i%15) == 0:\n",
    "        df_new.loc[i] = df_prueba.values[j]\n",
    "        if i != 0:\n",
    "            j=j+1\n",
    "    else:\n",
    "        df_new.loc[[i], ['ID']] = df_prueba.loc[[j], ['ID']]\n",
    "        df_new.loc[[i], ['oldID']] = df_prueba.loc[[j], ['oldID']]\n",
    "        df_new.loc[[i], ['fecha']] = df_prueba.loc[[j], ['fecha']]\n",
    "        df_new.loc[[i], ['periodo_integracion']] = 1\n",
    "        df_new.loc[[i], ['KM']] = df_prueba.loc[[j], ['KM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporto a CSV el DataFrame\n",
    "\n",
    "df_new.to_csv('df_M30_KM_dia_perinterpol.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('df_M30_KM_dia_perinterpol.csv', delimiter=';')\n",
    "#df_new.plot.scatter(x=\"Hora\", y=\"densidad\")\n",
    "#df_new.plot.scatter(x=\"Hora\", y=\"KM\", c=\"vmed\", colormap='viridis')\n",
    "\n",
    "df_new = df_new.sort_values(by=['KM', 'Hora'])\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new = df_new[['ID', 'oldID', 'fecha', 'intensidad', 'ocupacion', 'vmed', 'periodo_integracion',\n",
    "                       'KM', 'densidad', 'Hora']]\n",
    "df_new = df_new[~(df_new['KM'] == 0.2)]\n",
    "df_new = df_new[~(df_new['KM'] == 0.9)]\n",
    "df_new.index = range(len(df_new.index))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(df_new.KM, df_new.Hora, df_new.vmed, c=df_new.vmed, cmap='magma');\n",
    "\n",
    "#Axes3D.scatter(xs=df_new.Hora, ys=df_new.KM, zs=df_new.vmed, zdir='z', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import decimal\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolo.\n",
    "\n",
    "df = pd.read_csv('df_M30_KM_dia.csv', delimiter=',')\n",
    "\n",
    "df = df.sort_values(by=['KM', 'Hora'])\n",
    "df = df.reset_index(drop=True)\n",
    "df = df[['ID', 'oldID', 'fecha', 'intensidad', 'ocupacion', 'vmed', 'periodo_integracion',\n",
    "                       'KM', 'densidad', 'Hora']]\n",
    "df = df[~(df['KM'] == 0.2)]\n",
    "df = df[~(df['KM'] == 0.9)]\n",
    "df.index = range(len(df.index))\n",
    "\n",
    "df_temp = pd.DataFrame([])\n",
    "\n",
    "for id in np.sort(df.oldID.value_counts().keys()):\n",
    "     print(\"oldID: \", id)\n",
    "    df_aux = df.loc[df['oldID'] == id]\n",
    "    # Se crea la matriz de interpolación de tamaño: filas del id obtenido * 15 minutos interpolados\n",
    "    #- 14 últimos minutos del día sin medición * 10 columnas\n",
    "    nans = np.where(np.empty_like(np.arange((len(df_aux.index)*15-14)*10).reshape(len(df_aux.index)*15-14, 10)), np.nan, np.nan)\n",
    "    df_new = pd.DataFrame(nans, columns=['ID','oldID','fecha','intensidad','ocupacion','vmed','periodo_integracion', \n",
    "                                         'KM', 'densidad', 'Hora'])\n",
    "    j = 0\n",
    "    for i in df_new.index.values.astype(int):\n",
    "        if (i%15) == 0:\n",
    "            if i != 0:\n",
    "                j=j+1\n",
    "            df_new.loc[i] = df_aux.values[j]\n",
    "        else:\n",
    "            df_new.iloc[i, df.columns.get_loc('ID')] = df_aux.iloc[j, df.columns.get_loc('ID')]\n",
    "            df_new.iloc[i, df.columns.get_loc('oldID')] = df_aux.iloc[j, df.columns.get_loc('oldID')]\n",
    "            df_new.iloc[i, df.columns.get_loc('fecha')] = df_aux.iloc[j, df.columns.get_loc('fecha')]\n",
    "            df_new.iloc[i, df.columns.get_loc('periodo_integracion')] = 1.0\n",
    "            df_new.iloc[i, df.columns.get_loc('KM')] = df_aux.iloc[j, df.columns.get_loc('KM')]\n",
    "    \n",
    "    \n",
    "    df_int['intensidad'] = df_new['intensidad'].interpolate()\n",
    "    df_int['ocupacion'] = df_new['ocupacion'].interpolate()\n",
    "    df_int['vmed'] = df_new['vmed'].interpolate()\n",
    "    df_int['densidad'] = df_new['densidad'].interpolate()\n",
    "    #df_int['Hora'] = df_new['Hora'].interpolate()\n",
    "    if id == 'PM10001':\n",
    "        df_temp = df_int\n",
    "    else:\n",
    "        df_temp = df_temp.append(df_int, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporto a CSV el DataFrame\n",
    "\n",
    "df_good.to_csv('df_M30_KM_dia_inter_temp.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('df_M30_KM_dia_inter_temp.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esp = pd.DataFrame([])\n",
    "df_int = pd.DataFrame([])\n",
    "\n",
    "df_good.Hora.round(2)\n",
    "\n",
    "for time in np.sort(df_good.Hora.value_counts().keys()):\n",
    "    print(\"Hora:\", time)\n",
    "    df_aux = df_good.loc[df_good['Hora'] == time]\n",
    "    df_aux = df_aux.sort_values(by=['KM'])\n",
    "    df_aux = df_aux.reset_index(drop=True)\n",
    "    df_aux = df_aux.drop(columns=['Unnamed: 0'])\n",
    "    \n",
    "    nans = np.where(np.empty_like(np.arange(325*10).reshape(325, 10)), np.nan, np.nan)\n",
    "    df_new = pd.DataFrame(nans, columns=['ID','oldID','fecha','intensidad','ocupacion','vmed','periodo_integracion','KM','densidad','Hora'])\n",
    "    \n",
    "    df_new['ID'] = 'int_temp'\n",
    "    df_new['oldID'] = 'int_temp'\n",
    "    df_new['Hora'] = time\n",
    "    df_new['fecha'] = df_aux.iloc[0, df_aux.columns.get_loc('fecha')]\n",
    "    df_new['periodo_integracion'] = 1.0\n",
    "    \n",
    "    #for km in df_aux['KM'].diff():\n",
    "        #print(\"KM:\", km)\n",
    "    #    if not math.isnan(km):\n",
    "            #print(\"km:\", round(km, 1), \"Size:\", int(round((km/0.1)*10,1)), \"Shape:\", int(round(km/0.1,1)))\n",
    "    #        nans = np.where(np.empty_like(np.arange(int(round((km/0.1)*10, 1))).reshape(int(round((km/0.1), 1)), 10)), np.nan, np.nan)\n",
    "    #        df_new = pd.DataFrame(nans, columns=['ID','oldID','fecha','intensidad','ocupacion','vmed','periodo_integracion','KM','densidad','Hora'])\n",
    "            \n",
    "    #        df_new['ID'] = 'int_temp'\n",
    "    #        df_new['oldID'] = 'int_temp'\n",
    "    #        df_new['Hora'] = time\n",
    "    #        df_new['fecha'] = df_aux.iloc[0, df_aux.columns.get_loc('fecha')]\n",
    "    #        df_new['periodo_integracion'] = 1.0\n",
    "            \n",
    "    #        df_int = df_int.append(df_new, ignore_index=True)\n",
    "    \n",
    "    #print(\"Assigning values\")\n",
    "    j=0\n",
    "    k = 0\n",
    "    for i in df_new.index.values.astype(int):\n",
    "        print(\"i:\", i, \"KM:\", int(round(np.sort(df_good.KM.value_counts().keys())[k]/0.1, 1)))\n",
    "        if i == int(round(np.sort(df_good.KM.value_counts().keys())[k]/0.1, 1)):\n",
    "            print(\"Asigned\")\n",
    "            df_new.loc[i] = df_aux.loc[j].values\n",
    "            j += 1\n",
    "            k += 1\n",
    "            \n",
    "    print(\"Interpolating\")\n",
    "    #df_int_esp = df_int.interpolate()\n",
    "    #if id == 'PM10001':\n",
    "        #df_esp = df_int_esp\n",
    "    #else:\n",
    "        #df_esp = df_esp.append(df_int_esp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_esp.plot.scatter(x=\"Hora\", y=\"densidad\")\n",
    "df_esp.plot.scatter(x=\"Hora\", y=\"KM\", c=\"vmed\", colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
